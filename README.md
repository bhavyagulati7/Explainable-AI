# Explainable-AI
This repository contains Colab notebooks demonstrating the use of Explainable AI (XAI) techniques. The notebooks focus on IoT attack detection using a random forest classifier model and the application of LIME to explain the results of an image classification model.

# What is Explainable Artifitial Intelligence(XAI) ?
XAI helps users to understand why a complex AI model(blackbox models) gave a particular output by telling what were the features it observed before arriving at the result. This transparency enables users to gain insights into the model's reasoning process, ensuring that the results are interpretable and trustworthy.

# Notebooks
1. Original_NSL_KDD.ipynb: Demonstrates the detection of IoT attacks using a random classifier model for the NSL-KDD dataset.
2. TON_IOT.ipynb: Demonstrates the detection of IoT attacks using a random classifier model for the TON-IOT dataset.
3. LIME_Image_Classification.ipynb: Applies LIME to explain the results of an image classification model.
